{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Hyperparameter tuning on Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Example from https://stackoverflow.com/questions/43533610/how-to-use-hyperopt-for-hyperparameter-optimization-of-keras-deep-learning-netwo"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Step 0: Load required packages and create a toy-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features size:   6000 x 30\n",
      "Testing features size:    2000 x 30\n",
      "Validation features size: 2000 x 30\n",
      "\n",
      "Y_train\n",
      "Class: 0, Count: 3007, Percentage: 50.1%\n",
      "Class: 1, Count: 2993, Percentage: 49.9%\n",
      "\n",
      "Y_test\n",
      "Class: 0, Count: 998, Percentage: 49.9%\n",
      "Class: 1, Count: 1002, Percentage: 50.1%\n",
      "\n",
      "Y_validation\n",
      "Class: 0, Count: 990, Percentage: 49.5%\n",
      "Class: 1, Count: 1010, Percentage: 50.5%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta, Adam, rmsprop\n",
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "seed = 42 # Set seed for reproducibility purposes\n",
    "metric = 'accuracy' # See other options https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "kFoldSplits = 5\n",
    "\n",
    "np.random.seed(seed) # Set numpy seed for reproducibility\n",
    "\n",
    "# Create a toy-dataset using make_classification function from scikit-learn\n",
    "X,Y=make_classification(n_samples=10000,\n",
    "                        n_features=30,\n",
    "                        n_informative=2,\n",
    "                        n_redundant=10,\n",
    "                        n_classes=2,\n",
    "                        random_state=seed)\n",
    "\n",
    "# Split in train-test-validation datasets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=0.25, random_state=seed) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Check on created data\n",
    "print(\"Training features size:   %s x %s\\nTesting features size:    %s x %s\\nValidation features size: %s x %s\\n\" % (X_train.shape[0],X_train.shape[1], \n",
    "                                                                                                                     X_test.shape[0],X_test.shape[1], \n",
    "                                                                                                                     X_validation.shape[0],X_validation.shape[1]))\n",
    "\n",
    "# Create a function to print variable name\n",
    "def namestr(obj, namespace = globals()):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "# Check on class distribution\n",
    "for x in [Y_train, Y_test, Y_validation]:\n",
    "    print(namestr(x)[0])\n",
    "    counter = Counter(x)\n",
    "    for k,v in counter.items():\n",
    "        pct = v / len(x) * 100\n",
    "        print(\"Class: %1.0f, Count: %3.0f, Percentage: %.1f%%\" % (k,v,pct))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "y = Y_train\n",
    "X_val = X_test\n",
    "y_val = Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "### Step 1: Initialize space or a required range of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_options = np.arange(32, 1024 + 1, 32, dtype=int)\n",
    "dropout_options = np.arange(.20,.75 + 0.01, 0.025, dtype=float)\n",
    "batchsize_options = np.arange(32, 128 + 1, 32, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {'choice': hp.choice('num_layers',\n",
    "                            [ {'layers':'two', },\n",
    "                              {'layers':'three',\n",
    "                                    'units3': hp.choice('units3', units_options), \n",
    "                                    'dropout3': hp.choice('dropout3', dropout_options)}\n",
    "                            ]),\n",
    "\n",
    "            'units1': hp.choice('units1', units_options),\n",
    "            'units2': hp.choice('units2', units_options),\n",
    "\n",
    "            'dropout1': hp.choice('dropout1', dropout_options),\n",
    "            'dropout2': hp.choice('dropout2', dropout_options),\n",
    "\n",
    "            'batch_size' : hp.choice('batch_size', batchsize_options),\n",
    "\n",
    "            'nb_epochs' :  10,\n",
    "            'optimizer': hp.choice('optimizer',['adadelta','adam','rmsprop']),\n",
    "            'activation': 'relu'\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Step 2: Define objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_nn(params):   \n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=params['units1'], input_dim = X.shape[1])) \n",
    "    model.add(Activation(params['activation']))\n",
    "    model.add(Dropout(params['dropout1']))\n",
    "\n",
    "    model.add(Dense(units=params['units2'], kernel_initializer = \"glorot_uniform\")) \n",
    "    model.add(Activation(params['activation']))\n",
    "    model.add(Dropout(params['dropout2']))\n",
    "\n",
    "    if params['choice']['layers']== 'three':\n",
    "        model.add(Dense(units=params['choice']['units3'], kernel_initializer = \"glorot_uniform\")) \n",
    "        model.add(Activation(params['activation']))\n",
    "        model.add(Dropout(params['choice']['dropout3']))    \n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'])\n",
    "\n",
    "    model.fit(X, y, epochs=params['nb_epochs'], batch_size=params['batch_size'], verbose = 0)\n",
    "\n",
    "    pred_auc = model.predict_proba(X_val, batch_size = 128, verbose = 0)\n",
    "    acc = roc_auc_score(y_val, pred_auc)\n",
    "    print(\"AUC: %.5f\" % (acc))\n",
    "\n",
    "    return {'loss': -acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Step 3: Run Hyperopt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.96918\n",
      "AUC: 0.97183\n",
      "AUC: 0.96849\n",
      "AUC: 0.97238\n",
      "AUC: 0.96847\n",
      "100%|██████████| 5/5 [00:44<00:00,  9.00s/trial, best loss: -0.972379889519558]\n",
      "\n",
      "Best params found:\n",
      " {'batch_size': 2, 'dropout1': 19, 'dropout2': 6, 'dropout3': 5, 'num_layers': 1, 'optimizer': 0, 'units1': 26, 'units2': 25, 'units3': 25}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(f_nn, space, algo=tpe.suggest, max_evals=5, trials=trials)\n",
    "print('\\nBest params found:\\n', best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
